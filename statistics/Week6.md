# 통계학 6주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_6th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

6주차는 `2부-데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다


## Statistics_6th_TIL

### 2부. 데이터 분석 준비하기

### 11. 데이터 전처리와 파생변수 생성

<!-- 11. 데이터 전처리와 파생변수 생성에서 11.1 결측값 처리부터 11.4 데이터 표준화와 정규화 스케일링 파트까지 진행해주시면 됩니다. -->

## Study ScheduleStudy Schedule

| 주차  | 공부 범위     | 완료 여부 |
| ----- | ------------- | --------- |
| 1주차 | 1부 p.2~46    | ✅         |
| 2주차 | 1부 p.47~81   | ✅         |
| 3주차 | 2부 p.82~120  | ✅         |
| 4주차 | 2부 p.121~167 | ✅         |
| 5주차 | 2부 p.168~202 | ✅         |
| 6주차 | 2부 p.203~250 | ✅         |
| 7주차 | 2부 p.251~299 | 🍽️         |

> 과제가 많이 남지 않았습니다. 조금만 더 화이팅해주세요!

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리 

## 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```

### 11.1. 결측값 처리

<img width="500" height="300" alt="image" src="https://github.com/user-attachments/assets/3b16c717-f716-498d-90c2-f091f63fdf31" />

1. 결측값 처리 방법을 결정하기 전에 데이터 탐색을통해 결측값의 비율이 어떻게 되는지, 한 변수에 결측값이 몰려 있지는 않은지 등을 파악해야 함
2. 결측값은 분석 환경에 따라 '.', 'NA', 'NAN' 등으로 표시됨
3. 결측치가 발생하는 특성에 따라 세가지 종류로 분류됨

#### 완전 무작위 결측(MCAR)
- 결측값이 무작위로 발생한 경우
- 결측값을 포함한 데이터를 제거해도 편향이 거의 발생되지 않음

#### 무작위 결측(MAR)
- 다른 변수의 특성에 의해 해당 변수의 결측치가 체계적으로 발생한 경우
- 결측값은 특성에 영향을 받음

#### 비무작위 결측(NMAR)
- 결측값들이 해당 변수 자체의 특성을 받고 있는 경우
- 결측된 값은 실제로 무엇인지 확인할 수 없으므로 비무작위 결측을 구분하는 것은 어려움

#### 결측값 처리 방법

#### 표본 제거 방법: 가장 간단한 결측값 처리 방법
- 결측값이 심하게 많은 변수를 제거
- 결측값이 포함된 행을 제외하고 데이터 분석을 하는 표본 제거 방법을 사용
- 전체 데이터에서 결측값 비율이 10% 미만일 경우 이 방법을 사용

##### 평균 대치법
- 결측값을 제외한 온전한 값들의 평균을 구한 다음, 그 평균 값을 결측값들에 대치
- 유사 방법: 최빈값, 중앙값, 최댓값, 최솟값 대치
- 장점: 사용하기 간단하고 결측 표본 제거 방법의 단점을 어느정도 보완해줌
- 단점: 관측됭 데이터의 평균을 사용하기 때문에 통계량의 평균 오차가 왜곡되어 축소되어 나타나고, 따라서 p-value가 부정확하게 됨
- 표본제거방법과 평균 대치법은 완전 무작위 결측이 아닌 경우 적절하지 않음

##### 보간법

<img width="500" height="300" alt="image" src="https://github.com/user-attachments/assets/01291674-2419-4fd1-94a5-7a02997e84fb" />

- 시점 인덱스의 간격이 불규칙하거나 결측값이 두 번 이상 연달아 있을 때는 선형적인 수치 값을 계산해 보간하는 방법을 사용
- 데이터를 시간 순으로 정렬해야 함

##### 회귀 대치법
- 해당 변수와 다른 변수 사이의 관계성을 고려하여 결측값을 계산하면 보다 합리적으로 결측값을 처리할 수 있음
- 회귀식을 이용하여 결측값을 추정
- 추정하고자 하는 결측값을 가진 변수를 종속변수로 하고, 나머지 변수를 독립 변수로 하여 추정한 회귀식을 통해 결측값을 대치하는 것
- 결측된 변수의 분산을 과소 추정하는 문제를 가짐
  - 이러한 문제를 해결하기 위해 인위적으로 회귀식에 확률 오차항을 추가하는 확률적 회귀대치법을 사용하여 변동성을 조정하기도 함
 
##### 다중 대치법

<img width="500" height="300" alt="image" src="https://github.com/user-attachments/assets/abbebfce-e43f-4731-8b0f-6ace31e61f91" />

- 단순 대치법들의 표본오차 과소 추정 문제를 해결하기 위해 쵝ㄴ 많이 사용되는 방법
- 3단계로 구분할 수 있음
  1. 대치 단계: 가능한 대치 값의 분포에서 추출된 서로 다른 값으로 결측치를 처리한 n개의 데이터셋 생성
  2. 분석 단계: 생성된 각각의 데이터셋을 분석하여 모수의 추정치와 표준오차 계산
  3. 결합 단계: 계산된 각 데이터셋의 추정치와 표준오차를 결합하여 최종 결측 대치값 산출
- 대치 단계에서는 일반적으로 몬테카를로 방법이나 연쇄방정식을 통한 다중대치를 사용하여 대치값을 임의로 생성
- 가상 데이터는 5개 내외 정도만 생성해도 성능에 큰 문제가 없음
- 결측값의 비율이 증가할수록 가상 데이터도 많이 생성해야 검정력이 증가함
- 평균 공식을 통해 각각 데이터셋의 상이한 추정치와 표준오차를 결합하여 결측치가 채워진 최종 데이터셋을 만들면 다중 대치법의 모든 단계가 완료됨

#### 결측값 처리 실습
- 컬럼별로 non-null의 수가 다르면 결측값이 존재한다는 뜻
- dropna(): 결측값의 관측치 제거 함수
  - how = 'all': 모든 컬럼의 값이 결측값인 행을 제거할 때 사용하는 옵션
  - how = 'any': 한 컬럼이라도 결측값인 행을 제외할 때 사용하는 옵션
  - fillna(): 기본적인 결측값 대치를 수행하는 옵션
- 전 시점이나 뒤 시점의 값과 동일한 값으로 대치하는 보간법은 method 옵션을 pad나 bfill로 설정
  - 앞 시점의 값을 가졍로 때는 첫 행이 결측값인 경우, 앞 시점의 데이터가 없기 때문에 대치가 되지 않음
  - 뒤 시점을 가져올 때는 마지막 행이 결측값이면 대치가 되지 않음
- 시점 인덱스를 사용하기 위해서는 우선 시간형 컬럼을 시계열 객체로 변환한 후에 인덱스로 설정해줘야 함
  - 그 다음 interpolate() 함수를 사용하여 시점의 정도를 고려한 대치값을 적용
- 다중 대치는 sklearn의 impute 패키지를 활용
  - 대치에 필요없는 컬럼을 제거한 다음 다중 대치 알고리즘을 적용
  - 다중 대치를 적용할 때는 넘파이 배열로 변환되기 때문에 다시 판다스 데이터프레임으로 변환해줌


### 11.2. 이상치 처리

<img width="500" height="300" alt="image" src="https://github.com/user-attachments/assets/5218b1ef-f6ca-475e-b585-8108b14e6c38" />

1. 이상치: 일부 관측치의 값이 전체 데이터의 범위에서 크게 벗어난 아주 작거나 큰 극단적인 값을 갖는 것
2. 데이터의 모집단 평균이나 총합을 추정하는 것에 문제를 일으킴
3. 분산을 과도하게 증가시켜 분석이나 모델링의 정확도를 감소시키기 때문에 제거해야 함
4. 전체 데이터의 양이 많을수록 튀는 값이 통곗값에 미치는 영향력이 줄어들어 이상치 제거의 필요성이 낮아짐
5. 이상치는 해당 값을 결측값으로 대체한 다음 결측값 처리를 하거나, 아예 해당 이상치를 제거하는 것이 가장 간단
   - 추정치의 분산은 감소하지만 실곗값을 과장하여 편향을 방생시킴
   - 대처 방법
     - 관측값 변경: 하한 값과 상한 값을 결정한 후 하한 값보다 작으면 하한 값으로 대체하고 상한 값보다 크면 상한 값으로 대체
     - 가중치 조정: 이상치의 영향을 감소시키는 가중치를 주는 방법

#### 이상치 식별 방법

1. 이상치를 확인하는 방법
   - 데이터 분포를 통해 이상치가 얼마나 포함되어 있는지 가늠
   - 박스플롯 상에서 분류된 극단치를 그대로 선정하는 방법
   - 임의로 허용범위를 설정하여 이를 벗어나는 자료를 이상치로 정의하는 방법
   - 일반적으로 표준편차는 3으로 두지만, 분포가 비대칭인 경우 -표준편자와 +표준편차 값을 서로 다르게 설정하기도 함
   - 평균은 이상치에 통계량이 민감하게 변하기 때문에, 이상치에 보다 강건한 중위수와 중위수 절대편차를 사용하는 것이 좀 더 효과적

<img width="400" height="200" alt="image" src="https://github.com/user-attachments/assets/e024b1fa-b0a6-4661-98f0-221c2826ac6c" />

2. 통계치를 통한 무조건적인 이상치 탐색은 위험할 수 있음
   - 효과적인 이상치 탐색을 위해서는 해당 데이터 변수들의 의미와 비즈니스 도메인을 먼저 이해하고, 이상치가 생긴 원인을 논리적으로 생각하여 데이터를 바라봐야 함
   - 이상치를 변수화하여 이상치에 대한 설명력을 추가할 수 있음
  
<img width="600" height="300" alt="image" src="https://github.com/user-attachments/assets/6b137bc7-70f2-4464-ba24-e6111fa6205d" />

3. 분석 도메인에 따라 이상치가 중요한 분석 요인일 수 있음
   - 특히 제조 공정 데이터 분석의 경우, 데이터 이상치가 분석의 주요한 요소가 됨

### 11.3. 변수 구간화

<img width="500" height="300" alt="image" src="https://github.com/user-attachments/assets/5a3045d2-940f-4e9c-9aaf-9deed16c19d4" />

1. 변수 구간화: 데이터 분석의 성능을 향상시키기 위해 혹은 해석의 편리성을 위해 이산형 변수를 범주형 변수로 변환하는 것
   - 예: 숫자로 이루어진 나이 변수를 10대/20대/30대와 같이 특정 간격으로 나누거나 청소년/청년/중장년과 같이 특정 의미 기준으로 나눔
   - 각 범주에 해당되는 관측치의 수가 유사해지도록 하여 범주별 분포가 일정하도록 구간화할 수도 있음
2. 이산형 범주를 범주형 변수로 비즈니스적 상황에 맞도록 변환시킴으로써 데이터의 해석이나 예측, 분류 모델을 의도에 맞도록 유도할 수 있음
3. 흔한 경우는 아니지만 이산 값을 평활화하여 단순한 이산 값으로 변환시키는 기법을 사용하기도 함
   - 변수의 값을 일정 폭이나 빈도로 구간을 나눈 후, 각 구간 안에 속한 데이터 값을 평균, 중앙값, 경곗값 등으로 변환

<img width="1000" height="1200" alt="image" src="https://github.com/user-attachments/assets/0b8e85b5-f384-4384-bd51-13e5e3d80cd2" />

3. 클러스터링이나 의사결정나무와 같은 머신러닝 기법을 사용하여 구간을 나눌 수도 있음
   - 클러스터링은 타킷 변수를 설정할 필요 없이 구간화할 변수의 값들을 유사한 수준끼리 묶어줄 수 있음
   - 의사결정나무는 타깃 변수를 설정하여 구간화할 변수의 값을 타깃 변수 예측에 가장 적합한 구간으로 나누어 줌

#### 구간화 확인
- 변숫값이 효과적으로 구간화됐는지는 WOE값, IV값 등을 통해 측정 가능
  - 종속변수 대비 독립변수가 예측력이 얼마나 강한지를 나타내는 지표
  - IV 수치가 높을수록 종속변수의 True와 False를 잘 구분할 수 있는 정보량이 많다는 뜻
  - 변수가 종속변수를 제대로 설명할 수 있도록 구간화가 잘되면 IV값이 높아짐
  - 일반적으로 IV값이 0.3보다 큰 경우, 예측력이 우수한 변수인 것으로 판단단

### 11.4. 데이터 표준화와 정규화 스케일링

<img width="500" height="300" alt="image" src="https://github.com/user-attachments/assets/53e6e5df-2b3c-4193-a8c7-0fc145617095" />

1. 독립 변수들이 서로 단위가 다르거나 편차가 심할 때 값의 스케일링을 일정한 수준으로 변환시켜주는 표준화와 정규화 스케일링을 함
2. 독립변수 간 단위가 다른 것은 그대로 사용해도 무방하지만, 표준화나 정규화는 특정 머신러닝 모델의 학습 효율을 증가시키기 때문에 많이 사용됨
3. 해석적 관점에서 데이터 표준화와 정규화는 매우 유용함

#### 표준화

<img width="400" height="200" alt="image" src="https://github.com/user-attachments/assets/2a5e4255-ad9d-400b-89b6-c850249b47bf" />

- 각 관측치의 값이 전체 평균을 기준으로 어느 정도 떨어져 있는지 나타낼 때 사용
- 평균은 0으로 변환됨
- n표준편차 거리는 ±n으로 변환됨
- Z-score: Zero-mean으로부터 얼마나 떨어져 있는지를 나타냄
- 각 관측치 값에서 평균을 빼준 후 표준편차로 나눠주면 됨

> <img width="100" height="80" alt="image" src="https://github.com/user-attachments/assets/dcb1676c-f4e1-4854-8450-9e886fa8a8ee" />

#### 정규화

<img width="400" height="200" alt="image" src="https://github.com/user-attachments/assets/1bc0d8fb-5735-4e50-bbb0-72127ff81906" />

- 데이터의 범위를 0부터 1까지로 변환하여 데이터 분포를 조정하는 방법
- 전체 데이터 중에서 해당 값이 어떤 위치에 있는지 파악하는 데에 유용
- 0에 가까울수록 작은 값이고 1에 가까울수록 큰 값임
- 정규화는 (해당값 - 최솟값) / (최댓값 - 최솟값)을 해주면 됨

> <img width="100" height="60" alt="image" src="https://github.com/user-attachments/assets/650c3d1d-e60d-4841-8932-ef4c44edda2c" />

#### 정리
1. 표준화는 평균에서 얼마나 떨어져있는지를 나타내기 때문에 최댓값이 1이 될 수도, 8이 될 수도 있음
2. 정규화의 최댓값은 1, 최솟값은 0으로 직관적으로 표현됨
3. 정규화는 특정 값이 평균으로부터 어느정도 떨어져 있는지를 바로 알기 힘듦
4. 이 외에 기본 표준화, 정규화 방식은 이상치에 민감하다는 단점을 보완한 스케일링 기법은 RobustScaler도 많이 쓰임
  - 데이터의 중앙값(Q2)를 0으로 잡고, Q1과 Q3 사분위수와의 IQR 차이를 1이 되도록 하는 스케일링 기법
  - 이상치의 영향력을 최소화하여 일반적으로 표준화, 정규화보다 성능이 우수함
5. 표준화나 정규화는 거리를 활용한 군집분석에서 필수적임
6. 범주화 알고리즘 인공신경망 모델에서도 학습 효율과 분류 성능을 높이기 위해 표주노하나 정규화를 필수적으로 수행해야 함- 각 관측치의 값이 전체 평균을 기준으로 어느 정도 떨어져 있는지 나타낼 때 사용
- 평균은 0으로 변환됨
- n표준편차 거리는 ±n으로 변환됨
- Z-score: Zero-mean으로부터 얼마나 떨어져 있는지를 나타냄
- 각 관측치 값에서 평균을 빼준 후 표준편차로 나눠주면 됨

> <img width="100" height="80" alt="image" src="https://github.com/user-attachments/assets/dcb1676c-f4e1-4854-8450-9e886fa8a8ee" />

#### 정규화

<img width="400" height="200" alt="image" src="https://github.com/user-attachments/assets/1bc0d8fb-5735-4e50-bbb0-72127ff81906" />

- 데이터의 범위를 0부터 1까지로 변환하여 데이터 분포를 조정하는 방법
- 전체 데이터 중에서 해당 값이 어떤 위치에 있는지 파악하는 데에 유용
- 0에 가까울수록 작은 값이고 1에 가까울수록 큰 값임
- 정규화는 (해당값 - 최솟값) / (최댓값 - 최솟값)을 해주면 됨

> <img width="100" height="60" alt="image" src="https://github.com/user-attachments/assets/650c3d1d-e60d-4841-8932-ef4c44edda2c" />

#### 정리
1. 표준화는 평균에서 얼마나 떨어져있는지를 나타내기 때문에 최댓값이 1이 될 수도, 8이 될 수도 있음
2. 정규화의 최댓값은 1, 최솟값은 0으로 직관적으로 표현됨
3. 정규화는 특정 값이 평균으로부터 어느정도 떨어져 있는지를 바로 알기 힘듦
4. 이 외에 기본 표준화, 정규화 방식은 이상치에 민감하다는 단점을 보완한 스케일링 기법은 RobustScaler도 많이 쓰임
  - 데이터의 중앙값(Q2)를 0으로 잡고, Q1과 Q3 사분위수와의 IQR 차이를 1이 되도록 하는 스케일링 기법
  - 이상치의 영향력을 최소화하여 일반적으로 표준화, 정규화보다 성능이 우수함
5. 표준화나 정규화는 거리를 활용한 군집분석에서 필수적임
6. 범주화 알고리즘 인공신경망 모델에서도 학습 효율과 분류 성능을 높이기 위해 표주노하나 정규화를 필수적으로 수행해야 함


<br>
<br>

---

# 2️⃣ 확인 과제

> **교재에 있는 실습 파트를 직접 따라 해보세요. 실습을 완료한 뒤, 결과화면(캡처 또는 코드 결과)을 첨부하여 인증해 주세요.**
>
> **단순 이론 암기보다, 직접 손으로 따라해보면서 실습해 보는 것이 가장 확실한 학습 방법입니다.**
>
> > **인증 예시 : 통계 프로그램 결과, 시각화 이미지 캡처 등**

<!-- 이 주석을 지우고 “실습 결과 화면(캡처)을 이곳에 첨부해주세요.-->

~~~
인증 이미지가 없으면 과제 수행으로 인정되지 않습니다.
~~~



### 🎉 수고하셨습니다.
